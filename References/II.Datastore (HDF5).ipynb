{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDF5\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method create_dataset in module h5py._hl.group:\n",
      "\n",
      "create_dataset(name, shape=None, dtype=None, data=None, **kwds) method of h5py._hl.files.File instance\n",
      "    Create a new HDF5 dataset\n",
      "    \n",
      "    name\n",
      "        Name of the dataset (absolute or relative).  Provide None to make\n",
      "        an anonymous dataset.\n",
      "    shape\n",
      "        Dataset shape.  Use \"()\" for scalar datasets.  Required if \"data\"\n",
      "        isn't provided.\n",
      "    dtype\n",
      "        Numpy dtype or string.  If omitted, dtype('f') will be used.\n",
      "        Required if \"data\" isn't provided; otherwise, overrides data\n",
      "        array's dtype.\n",
      "    data\n",
      "        Provide data to initialize the dataset.  If used, you can omit\n",
      "        shape and dtype arguments.\n",
      "    \n",
      "    Keyword-only arguments:\n",
      "    \n",
      "    chunks\n",
      "        (Tuple) Chunk shape, or True to enable auto-chunking.\n",
      "    maxshape\n",
      "        (Tuple) Make the dataset resizable up to this shape.  Use None for\n",
      "        axes you want to be unlimited.\n",
      "    compression\n",
      "        (String or int) Compression strategy.  Legal values are 'gzip',\n",
      "        'szip', 'lzf'.  If an integer in range(10), this indicates gzip\n",
      "        compression level. Otherwise, an integer indicates the number of a\n",
      "        dynamically loaded compression filter.\n",
      "    compression_opts\n",
      "        Compression settings.  This is an integer for gzip, 2-tuple for\n",
      "        szip, etc. If specifying a dynamically loaded compression filter\n",
      "        number, this must be a tuple of values.\n",
      "    scaleoffset\n",
      "        (Integer) Enable scale/offset filter for (usually) lossy\n",
      "        compression of integer or floating-point data. For integer\n",
      "        data, the value of scaleoffset is the number of bits to\n",
      "        retain (pass 0 to let HDF5 determine the minimum number of\n",
      "        bits necessary for lossless compression). For floating point\n",
      "        data, scaleoffset is the number of digits after the decimal\n",
      "        place to retain; stored values thus have absolute error\n",
      "        less than 0.5*10**(-scaleoffset).\n",
      "    shuffle\n",
      "        (T/F) Enable shuffle filter.\n",
      "    fletcher32\n",
      "        (T/F) Enable fletcher32 error detection. Not permitted in\n",
      "        conjunction with the scale/offset filter.\n",
      "    fillvalue\n",
      "        (Scalar) Use this value for uninitialized parts of the dataset.\n",
      "    track_times\n",
      "        (T/F) Enable dataset creation timestamps.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('../Data/data.h5', 'w') as h5:\n",
    "    help(h5.create_dataset)\n",
    "    h5.create_dataset('nparray', data=np.arange(0, 10000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 dataset \"nparray\": shape (10000000,), type \"<i8\">\n",
      "[      0       1       2 ..., 9999997 9999998 9999999]\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('../Data/data.h5', 'r') as h5:\n",
    "    _data = h5.get('nparray')\n",
    "    print(_data)\n",
    "    arr = np.array(_data)\n",
    "    print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ItemsViewHDF5(<HDF5 file \"data.h5\" (mode r)>)\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('../Data/data.h5', 'r') as h5:\n",
    "    print(h5.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with h5py.File('../Data/data.h5', 'w') as h5:\n",
    "    grp = h5.create_group('dataitems')\n",
    "    grp.create_dataset('item1', data=np.arange(0, 1999999))\n",
    "    \n",
    "    sgrp = h5.create_group('dataitems/images')\n",
    "    sgrp.create_dataset('image1', data=np.arange(0, 886888))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ItemsViewHDF5(<HDF5 file \"data.h5\" (mode r)>)\n",
      "<HDF5 group \"/dataitems\" (2 members)>\n",
      "<HDF5 dataset \"item1\": shape (1999999,), type \"<i8\">\n",
      "<HDF5 dataset \"item1\": shape (1999999,), type \"<i8\">\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('../Data/data.h5', 'r') as h5:\n",
    "    print(h5.items())\n",
    "    print(h5.get('dataitems'))\n",
    "    print(h5.get('dataitems').get('item1'))\n",
    "    print(h5.get('dataitems/item1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
